{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Données COVID-19 Australie: exploration et nettoyage\n",
    "\n",
    "Test évaluation pour le poste Inria / AP-HP - notebook 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importation des données et des librairies python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install pandas-dedupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import pandas_dedupe\n",
    "import recordlinkage\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(sqlite3.OperationalError) no such table: patient\n[SQL: select * from patient]\n(Background on this error at: http://sqlalche.me/e/13/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/media/marco/DATA1/media/marco/DATA1/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1277\u001b[0;31m                     self.dialect.do_execute(\n\u001b[0m\u001b[1;32m   1278\u001b[0m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/marco/DATA1/media/marco/DATA1/lib/python3.8/site-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such table: patient",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f329517bd789>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sqlite:///data.db'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mecho\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_patient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'select * from patient'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, parse_dates=['date_of_birth']) # dates are parsed into date and time format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf_pcr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'select * from test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/marco/DATA1/media/marco/DATA1/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[1;32m    430\u001b[0m         )\n\u001b[1;32m    431\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         return pandas_sql.read_query(\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/marco/DATA1/media/marco/DATA1/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize)\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1218\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1219\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/marco/DATA1/media/marco/DATA1/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1085\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m         \u001b[0;34m\"\"\"Simple passthrough to SQLAlchemy connectable\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1087\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnectable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m     def read_table(\n",
      "\u001b[0;32m/media/marco/DATA1/media/marco/DATA1/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, object_, *multiparams, **params)\u001b[0m\n\u001b[1;32m   1004\u001b[0m         \"\"\"\n\u001b[1;32m   1005\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_on_connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/marco/DATA1/media/marco/DATA1/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_text\u001b[0;34m(self, statement, multiparams, params)\u001b[0m\n\u001b[1;32m   1173\u001b[0m         \u001b[0mdialect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdialect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_distill_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m         ret = self._execute_context(\n\u001b[0m\u001b[1;32m   1176\u001b[0m             \u001b[0mdialect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m             \u001b[0mdialect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_ctx_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_statement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/marco/DATA1/media/marco/DATA1/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m             self._handle_dbapi_exception(\n\u001b[0m\u001b[1;32m   1318\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m             )\n",
      "\u001b[0;32m/media/marco/DATA1/media/marco/DATA1/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   1509\u001b[0m                 \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewraise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_traceback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mshould_wrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m                 util.raise_(\n\u001b[0m\u001b[1;32m   1512\u001b[0m                     \u001b[0msqlalchemy_exception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_traceback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m                 )\n",
      "\u001b[0;32m/media/marco/DATA1/media/marco/DATA1/lib/python3.8/site-packages/sqlalchemy/util/compat.py\u001b[0m in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;31m# credit to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/marco/DATA1/media/marco/DATA1/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1275\u001b[0m                             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1277\u001b[0;31m                     self.dialect.do_execute(\n\u001b[0m\u001b[1;32m   1278\u001b[0m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m                     )\n",
      "\u001b[0;32m/media/marco/DATA1/media/marco/DATA1/lib/python3.8/site-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute_no_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: (sqlite3.OperationalError) no such table: patient\n[SQL: select * from patient]\n(Background on this error at: http://sqlalche.me/e/13/e3q8)"
     ]
    }
   ],
   "source": [
    "engine = create_engine('sqlite:///data.db', echo=False)\n",
    "con = engine.connect()\n",
    "df_patient = pd.read_sql('select * from patient', con=con)#, parse_dates=['date_of_birth']) # dates are parsed into date and time format\n",
    "df_pcr = pd.read_sql('select * from test', con=con) \n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Données des patients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"size patients dataframe:\",df_patient.shape)\n",
    "df_patient[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('how many patients in total?')\n",
    "tot_patients = len(df_patient['patient_id'].unique())\n",
    "print(tot_patients, ' patients') #num. unique IDs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Résultats du PCR, test utilisé pour le diagnostic du Covid19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"size pcr dataframe:\",df_pcr.shape)\n",
    "df_pcr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('how many PCR in total?')\n",
    "# list of tested patients\n",
    "tested_list = df_pcr['patient_id'].unique() #List unique values in the PCR patients ID column\n",
    "tot_pcr = len(tested_list)\n",
    "print(tot_pcr, ' PCR') #num. unique IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Nettoyage des données - PCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('variables and types in pcr dataframe:')\n",
    "print('')\n",
    "print(df_pcr.dtypes) # variables and types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pcr_nodupes = df_pcr.drop_duplicates(subset=None, keep=\"first\", inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicateDFRow_pcr = df_pcr_nodupes[df_pcr_nodupes.duplicated()]\n",
    "print(' \\n PCR duplicates \\n', duplicateDFRow_pcr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicateID_pcr = df_pcr_nodupes[df_pcr_nodupes.duplicated(['patient_id'])]\n",
    "print(\"we have\", len(duplicateID_pcr.index), \"duplicated pcr IDs vs.\", len(duplicateDFRow_pcr.index), \"duplicate rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_pcr_id = df_pcr_nodupes.loc[df_pcr_nodupes['patient_id'].isin(duplicateID_pcr['patient_id'])]\n",
    "\n",
    "duplicate_pcr_id.sort_values(by=['patient_id'], inplace=True)\n",
    "\n",
    "duplicate_pcr_id[:10] #information to be removed since it is contradictory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pcr_clean = df_pcr_nodupes.loc[~df_pcr_nodupes['patient_id'].isin(duplicateID_pcr['patient_id'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Valeurs manquantes et standardisation résultats PCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('amount of empty cells in PCR dataframe columns: \\n', df_pcr_clean.isnull().sum(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_pcr_clean['pcr'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pcr_clean = df_pcr_clean.replace({'pcr': {'P': 'Positive', 'N': 'Negative'}}) # replace P and N with verbose values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('before cleaning',df_pcr.shape)\n",
    "print('after cleaning',df_pcr_clean.shape)\n",
    "df_pcr_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tested_IDlist_clean = df_pcr_clean['patient_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Nettoyage des données - patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- celles vides / valeurs manquantes\n",
    "\n",
    "- imputation celles vides et traitement des valeurs aberrants \n",
    "\n",
    "- typos dans la colonne états (state)\n",
    "\n",
    "- détection et suppression des doublons\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Valeurs manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Statistique celles vides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0 # initialize column count\n",
    "colnum = []\n",
    "colname = []\n",
    "nullpc = []\n",
    "for col in df_patient:\n",
    "    i +=1 # update the counter\n",
    "    nulsum = sum(pd.isnull(df_patient[col])) # sum of null value for the column (empty cells)\n",
    "    numrows = len(df_patient)\n",
    "    nuls_pourcent = (sum(pd.isnull(df_patient[col]))/numrows)*100 # % of null value for the column\n",
    "    r_nuls_pourcent = round(nuls_pourcent, 3) # return only the first 3 digits after the comma of the percentage float value\n",
    "    #create columnstats database\n",
    "    colnum.append(i) # first column: column number\n",
    "    colname.append(col) # column name\n",
    "    nullpc.append(r_nuls_pourcent) # % null values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nul = pd.DataFrame({'num':colnum, 'name':colname, '%null':nullpc})\n",
    "df_nul = df_nul.sort_values(by='%null', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(23,8))\n",
    "\n",
    "plt.bar(df_nul['name'], df_nul['%null'])\n",
    "plt.title('NaN % in the dataframe', color=\"red\", fontsize = 14)\n",
    "plt.ylabel('% empty cell in the column', color=\"red\", fontsize = 14)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.rcParams['figure.constrained_layout.use'] = True\n",
    "plt.savefig(\"null.png\", format=\"PNG\", dpi = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Imputation des valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('variables and types in patients dataframe:')\n",
    "print('')\n",
    "print(df_patient.dtypes) # variables and types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2.1 inputation variables numeriques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  - CAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient_filled = df_patient #initialize the dataframe to be filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to fill postcode values\n",
    "def postcode_filler(df):\n",
    "    df_patient_filled['postcode'] = df_patient_filled['postcode'].fillna('0000') # fill empty cells\n",
    "    df_patient_filled['postcode'] = df_patient_filled.apply(lambda cell: '0000' if len(cell['postcode']) > 4 else cell['postcode'], axis=1) # inputation of values that are not a postcode\n",
    "    df_patient_filled['postcode'] = df_patient_filled['postcode'].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient_filled = postcode_filler(df_patient_filled) # apply the function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  - numèro rue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient_filled.street_number.fillna(0) \n",
    "\n",
    "print('missing street numbers filled with 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  - dates de naissance et age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour traiter la variable \"date de naissance\" on pourrait la convertir en variable date comme on ferait avec la commande SQL \n",
    "\n",
    "select convert(date, convert(varchar(255), yyyymm) + '01')\n",
    "\n",
    "mais pour la comparer à l'age est plus interessant recuperer seulement l'année\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_from_sqldate(df, datecolumn):\n",
    "    datecolumn = datecolumn.fillna(19001101.0) # imputation des valeurs mancants avec 1900\n",
    "    df['dates'] = datecolumn.astype(str)\n",
    "    df['birth_year'] = [x[:4] for x in df_patient['dates']]\n",
    "    df['birth_year'] = df['birth_year'].astype(int)\n",
    "    del df['dates']\n",
    "    return df['birth_year'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_from_sqldate(df_patient_filled, df_patient_filled['date_of_birth']) # apply the function to the patients dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(df_patient_filled['birth_year']), max(df_patient_filled['birth_year'])) \n",
    "df_patient_filled['birth_year'] = df_patient_filled.apply(lambda cell: 1900 if cell['birth_year']<1900 else cell['birth_year'], axis=1)\n",
    "      \n",
    "print('correct dates earlier than 1900')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knowing that COVID-19 came to Australia in 2020, I can calculate the age subctracting the birthyear \n",
    "\n",
    "df_patient_filled[\"estimated_age\"] = 2020 - df_patient['birth_year'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling missing values with those calculated from birth year\n",
    "df_patient_filled['age']= df_patient_filled['age'].fillna(df_patient_filled[\"estimated_age\"])\n",
    "df_patient_filled['age']= df_patient_filled['age'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - valeurs aberrants age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "ax = sns.boxplot(x=df_patient_filled['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('null values:', sum(pd.isnull(df_patient_filled['age'])), \"no more empty cells!!!\")\n",
    "print('')\n",
    "print(len(df_patient_filled.loc[df_patient_filled['age'] < 0]), 'too young to be true')\n",
    "print(len(df_patient.loc[df_patient_filled['age'] >= 110]), 'too old to be true')\n",
    "print('max age:',max(df_patient_filled['age']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputation of average values for excessive values\n",
    "df_patient_filled['age'] = df_patient_filled.apply(lambda cell: cell['estimated_age'] if cell['age']<0 else cell['age'], axis=1) \n",
    "print('ages below 0 are unrealistic, they get replaced by that calculated from birth year')\n",
    "\n",
    "df_patient_filled['age'] = df_patient_filled.apply(lambda cell: cell['estimated_age'] if cell['age']>110 else cell['age'], axis=1) # imputation of average values for excessive values\n",
    "\n",
    "print('max age:',max(df_patient_filled['age']))\n",
    "print('if the patient given age exceeds this value, it is replaced by that calculated from birth year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2.2 inputation variables objet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - \"missing\" au lieu des valeurs mancants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_inputation(df):    \n",
    "    str_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "    df.loc[:, str_cols] = df.loc[:, str_cols].fillna('missing')\n",
    "    return df\n",
    "\n",
    "df_patient_filled = obj_inputation(df_patient_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - la variable état (state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beaucoup de typos et valeurs manquants dans la colonne \"state\". Il ne serait pas possible de faire une statistique basée sur les données brutes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On pourrait corriger les typos (ex. nxw = nsw) mais cette methode ne corrigerait pas des nouveaux typos. On cherche une methode plus robuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient_filled['state'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour corriger les erreurs et faire une imputation des valeurs manquants on essaye de recuperer les bonnes valeurs à partir des codes postales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici la liste des code postale associés à chaque état: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Postcodes_in_Australia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient_filled['state_inferred'] = df_patient_filled['postcode'] # initialize feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define lists of postcodes by state:\n",
    "# New South Wales\n",
    "NSW1 = np.arange(1000, 2600)\n",
    "NSW2 = np.arange(2619, 2900)\n",
    "NSW3 = np.arange(2921, 3000)\n",
    "NSW = list(np.concatenate((NSW1, NSW2, NSW3), axis=None)) # New South Wales postcodes\n",
    "#Australian Capital Territory\n",
    "ACT1 = np.arange(200, 300)\n",
    "ACT2 = np.arange(2600, 2619)\n",
    "ACT3 = np.arange(2900, 2921)\n",
    "ACT = list(np.concatenate((ACT1, ACT2, ACT3), axis=None)) #Australian Capital Territory postcodes\n",
    "#Victoria\n",
    "VIC1 = np.arange(3000, 4000)\n",
    "VIC2 = np.arange(8000, 9000)\n",
    "VIC = list(np.concatenate((VIC1, VIC2), axis=None)) #Victoria postcodes\n",
    "#Queensland\n",
    "QLD1 = np.arange(4000, 5000)\n",
    "QLD2 = np.arange(9000, 10000)\n",
    "QLD = list(np.concatenate((QLD1, QLD2), axis=None)) #Queensland postcodes\n",
    "#South Australia\n",
    "SA = list(np.arange(5000, 6000)) #South Australia postcodes\n",
    "#Western Australia\n",
    "WA = list(np.arange(6000, 7000)) #Western Australia postcodes\n",
    "#Tasmania\n",
    "TAS = list(np.arange(7000, 8000)) #Tasmania postcodes\n",
    "#Northern Territory\n",
    "NT = list(np.arange(800, 1000)) #Northern Territory postcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_list = ['nsw', 'act', 'vic', 'qld', 'sa', 'wa', 'tas', 'nt', 'missing']\n",
    "postcodes_list = [NSW, ACT, VIC, QLD , SA, WA, TAS, NT, [0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign state to each postcode in the list \n",
    "for i in np.arange(0,len(states_list)):\n",
    "    df_patient_filled['state_inferred']  = np.where(~df_patient_filled['postcode'].isin(postcodes_list[i]), df_patient_filled['state_inferred'] , states_list[i])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalement je vais exchanger les typos et les valeurs manquants de la colonne \"state\" avec ceux de la colonne \"inferred state\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AU_states_list = ['nsw', 'act', 'vic', 'qld', 'sa', 'wa', 'tas', 'nt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df_patient_filled['state']  = df_patient_filled.apply(lambda cell: cell['state_inferred'] if cell['state'].isin(AU_states_list) else cell['state'], axis=1)\n",
    "df_patient_filled['state_filled']  = np.where(df_patient_filled['state'].isin(AU_states_list), df_patient_filled['state'] , df_patient_filled['state_inferred'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient_clean = df_patient_filled # initialize the dataframe to get cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Exploration des variables clés pour detecter les doublons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1.1 Lignes identiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a function that detects repeated values in the dataframe\n",
    "duplicateDFRow_patient = df_patient_clean[df_patient_clean.duplicated()]\n",
    "print('total identical rows: ', len(duplicateDFRow_patient.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1.2 Doublons patient_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicateID_patient = df_patient_clean[df_patient_clean.duplicated(['patient_id'])]\n",
    "print(\"we have\", len(duplicateID_patient.index), \"duplicated patient IDs vs\", len(duplicateDFRow_patient.index), \"duplicate rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_patients_id = df_patient_clean.loc[df_patient_clean['patient_id'].isin(duplicateID_patient['patient_id'])]\n",
    "\n",
    "duplicate_patients_id.sort_values(by=['patient_id'], inplace=True)\n",
    "\n",
    "duplicate_patients_id[66:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient_clean['tested'] = df_patient_clean['patient_id']\n",
    "\n",
    "df_patient_clean['tested']  = np.where(df_patient_clean['patient_id'].isin(tested_IDlist_clean), 1 , 0) # assign 1 if patient_ID belongs to tested dataframe, 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('total_IDs labeled as tested in patient dataframe \\n before duplicates removal: ', sum(df_patient_clean['tested']),\"\\n unique tested IDs: \", len(tested_IDlist_clean), \"\\n duplicate tested IDs:\" , sum(df_patient_clean['tested'])-len(tested_IDlist_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = df_patient_clean.columns.tolist()\n",
    "#del col_list[1:3]\n",
    "\n",
    "print(col_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1.2 Doublons nom-prénom-CAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Du moment que on pourrait avoir des doublons avec numero de telephone manquant, on va créer une autre variable pour identifier au mieux les patients. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La jointure de nom+prénom donne des doublons mais beaucoup des valeurs identiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donc on ajoute le CAP et l'identificatif sera le nom/prenom/CAP des patients.\n",
    "Pour ca il faut joindre les trois variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient_clean['postcode_str']= df_patient_clean['postcode'].astype(str)\n",
    "df_patient_clean['name_postcode'] = df_patient_clean[['given_name', 'postcode_str']].apply(lambda x: ' '.join(x), axis=1)\n",
    "df_patient_clean['surname_postcode'] = df_patient_clean[['surname', 'postcode_str']].apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_pname = df_patient_clean[df_patient_clean.duplicated(['name_postcode'])]\n",
    "print(\"we have\", len(duplicate_pname.index), \"duplicated name+postcode vs\", len(duplicateDFRow_patient.index), \"duplicate rows\")\n",
    "duplicate_pname_id = df_patient_clean.loc[df_patient_clean['name_postcode'].isin(duplicate_pname['name_postcode'])]\n",
    "\n",
    "duplicate_pname_id.sort_values(by=['name_postcode'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_psurname = df_patient_clean[df_patient_clean.duplicated(['surname_postcode'])]\n",
    "print(\"we have\", len(duplicate_psurname.index), \"duplicated surname+postcode vs\", len(duplicateDFRow_patient.index), \"duplicate rows\")\n",
    "duplicate_psurname_id = df_patient_clean.loc[df_patient_clean['surname_postcode'].isin(duplicate_pname['surname_postcode'])]\n",
    "\n",
    "duplicate_psurname_id.sort_values(by=['surname_postcode'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria_tested_cap = c1 & c2 & c3\n",
    "criteria_not_tested_cap = c1 & c2 & c4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_duploCAP_tested = inner_join_df[criteria_tested_cap]\n",
    "print(df_duploCAP_tested.shape)\n",
    "df_duploCAP_tested.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CAP_tested = df_duploCAP_tested.drop_duplicates(subset=['phone_number'], keep='last')\n",
    "print(df_CAP_tested.shape)\n",
    "df_CAP_tested[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now deduplicate the records for non-tested patients\n",
    "df_duploCAP_nontested = inner_join_df[criteria_not_tested_cap]\n",
    "print('before deduplication', df_duploCAP_nontested.shape)\n",
    "df_CAP_nontested = df_duploCAP_nontested.drop_duplicates(subset=['phone_number'], keep='last')\n",
    "print('after deduplication', df_CAP_nontested.shape)\n",
    "df_CAP_nontested[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c7 = ~ df_CAP_nontested['postcode'].isin(df_CAP_tested['postcode']) \n",
    "\n",
    "dfCAP_outer = df_CAP_nontested[c7]\n",
    "df_no_CAP_dup = df_CAP_tested.append(dfCAP_outer)\n",
    "print(df_no_CAP_dup.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_pname_missingphone = df_no_CAP_dup.loc[df_no_CAP_dup['phone_number'] == 'missing']\n",
    "print(len(duplicate_pname_missingphone), \"duplicate name+surname+CAP with missing phone number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = outer_join_df.duplicated(['phone_number']) \n",
    "c2 = outer_join_df['postcode'] != \"missing\"\n",
    "\n",
    "c3 = outer_join_df['tested'] == 1\n",
    "c4 = outer_join_df['tested'] == 0\n",
    "#c5 = df_patient_clean.duplicated(['phone_number']) \n",
    "#c6 = df_patient_clean['phone_number'] != \"missing\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1.2 Doublons numéro de téléphone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_ph_n = df_patient_clean[df_patient_clean.duplicated(['phone_number']) & (df_patient_clean['phone_number'] != \"missing\")]\n",
    "print(\"we have\", len(duplicate_ph_n.index), \"duplicated phone numbers vs\", len(duplicateDFRow_patient.index), \"duplicate rows\")\n",
    "duplicate_phone_id = df_patient_clean.loc[df_patient_clean['phone_number'].isin(duplicate_ph_n['phone_number'])]\n",
    "\n",
    "duplicate_phone_id.sort_values(by=['phone_number'], inplace=True)\n",
    "\n",
    "duplicate_phone_id[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_carbon = df_carbon[df_carbon['carbon-footprint_100g'] > 1]\n",
    "#c3 = df_patient_clean.duplicated(['birth_year'])\n",
    "df_missingphones = df_patient_clean['phone_number'] == \"missing\"\n",
    "#c5 = df_patient_clean['estimated_age'] < 120\n",
    "duplicate_year_missingphone = df_missingphones[(df_missingphones.duplicated(['birth_year'])) & (df_missingphones['birth_year'] > 1900)]\n",
    "#duplicate_year_missingphone = duplicate_year_missingphone[df_patient_clean['estimated_age'] < 120]\n",
    "print(\"we have\", len(duplicate_year_missingphone.index), \"duplicated birth years with missing phone numbers vs\", len(duplicateDFRow_patient.index), \"duplicate rows\")\n",
    "duplicate_year_id = df_patient_clean.loc[df_patient_clean['birth_year'].isin(duplicate_year_missingphone['birth_year'])]\n",
    "\n",
    "duplicate_year_id.sort_values(by=['birth_year'], inplace=True)\n",
    "\n",
    "duplicate_year_id[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria_tested_ph = c5 & c6 & c3\n",
    "criteria_not_tested_ph = c5 & c6 & c4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_patient_clean[criteria_tested_ph]\n",
    "print(df1.shape)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1nodup = df1.drop_duplicates(subset=['phone_number'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_patient_clean[criteria_not_tested_ph]\n",
    "df2nodup = df2.drop_duplicates(subset=['phone_number'], keep='last')\n",
    "print(df1nodup.shape, df2nodup.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_no_phone_dup = pd.merge(df1nodup, df2nodup, on='phone_number', how='left')\n",
    "#print(df_no_phone_dup.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c7 = ~ df2nodup['phone_number'].isin(df1nodup['phone_number']) \n",
    "df2_outer = df2nodup[c7]\n",
    "df_no_phone_dup = df1nodup.append(df2_outer)\n",
    "print(df_no_phone_dup.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_phone_dup.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Fonction d'élimination des doublons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- on va retenir d'abord les valeurs si le patient-ID est parmi les IDs testés\n",
    "- en suite on va eliminer les autres doublons\n",
    "- la procedure est effectuée pour deux variables: numéro de telephone, puis nom+prenom+CAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![deduplication](deduplication_procedure.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://recordlinkage.readthedocs.io/en/latest/notebooks/data_deduplication.html\n",
    "dfA = df_patient_filled\n",
    "\n",
    "\n",
    "indexer = recordlinkage.Index()\n",
    "indexer.full()\n",
    "candidate_links = indexer.index(dfA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(dfA), len(candidate_links))\n",
    "# (1000*1000-1000)/2 = 499500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = recordlinkage.Index()\n",
    "indexer.block('given_name')\n",
    "candidate_links = indexer.index(dfA)\n",
    "\n",
    "print (len(candidate_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell can take some time to compute.\n",
    "compare_cl = recordlinkage.Compare()\n",
    "\n",
    "compare_cl.string('given_name', 'given_name', method='jarowinkler', threshold=0.85, label='given_name')\n",
    "compare_cl.string('surname', 'surname', method='jarowinkler', threshold=0.85, label='surname')\n",
    "compare_cl.exact('birth_year', 'birth_year', label='birth_year')\n",
    "compare_cl.exact('suburb', 'suburb', label='suburb')\n",
    "compare_cl.exact('state', 'state', label='state')\n",
    "compare_cl.string('address_1', 'address_1', threshold=0.85, label='address_1')\n",
    "\n",
    "features = compare_cl.compute(candidate_links, dfA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum the comparison results.\n",
    "features.sum(axis=1).value_counts().sort_index(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexation step\n",
    "indexer = recordlinkage.Index()\n",
    "indexer.block(left_on='given_name')\n",
    "candidate_links = indexer.index(dfA)\n",
    "\n",
    "# Comparison step\n",
    "compare_cl = recordlinkage.Compare()\n",
    "\n",
    "compare_cl.string('given_name', 'given_name', method='jarowinkler', threshold=0.85, label='given_name')\n",
    "compare_cl.string('surname', 'surname', method='jarowinkler', threshold=0.85, label='surname')\n",
    "compare_cl.exact('birth_year', 'birth_year', label='birth_year')\n",
    "compare_cl.exact('phone_number', 'phone_number', label='phone_number')\n",
    "compare_cl.exact('postcode', 'postcode', label='state')\n",
    "#compare_cl.string('address_1', 'address_1', threshold=0.9, label='address_1')\n",
    "\n",
    "features = compare_cl.compute(candidate_links, dfA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification step\n",
    "matches = features[features.sum(axis=1) > 3] # at least two matched features\n",
    "matches = matches.reset_index()\n",
    "print(len(matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
